{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2, os,random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the train data\n",
    "This part is to generate the data and the labels for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "train_dir='./input/train/'\n",
    "test_dir='./input/test/'\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "train_file=[train_dir+img for img in os.listdir(train_dir)]\n",
    "number=range(0,12500)\n",
    "random.shuffle(number)\n",
    "number=number[0:2000]\n",
    "train=[]\n",
    "cat_label=[0]\n",
    "dog_label=[1]\n",
    "for i in tqdm(number):\n",
    "    cat_path=train_dir+'cat.'+str(i)+'.jpg'\n",
    "    img = image.load_img(cat_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    cat_data = preprocess_input(x)\n",
    "    cat_data=model.predict(cat_data)\n",
    "\n",
    "   \n",
    "    dog_path=train_dir+'dog.'+str(i)+'.jpg'\n",
    "    img = image.load_img(dog_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    dog_data = preprocess_input(x)\n",
    "    dog_data=model.predict(dog_data)\n",
    "   \n",
    "    train.append([np.array(cat_data[0]),np.array(cat_label)])\n",
    "    train.append([np.array(dog_data[0]),np.array(dog_label)])\n",
    "np.save('train_4000.npy',train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train the Model\n",
    "This part is to build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "3000/3000 [==============================] - 13s - loss: 2.7973 - acc: 0.8223 - val_loss: 0.7991 - val_acc: 0.9500\n",
      "Epoch 2/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1166 - acc: 0.8053 - val_loss: 0.7991 - val_acc: 0.9500\n",
      "Epoch 3/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.0411 - acc: 0.8100 - val_loss: 0.7991 - val_acc: 0.9500\n",
      "Epoch 4/30\n",
      "3000/3000 [==============================] - 12s - loss: 2.9081 - acc: 0.8183 - val_loss: 0.7991 - val_acc: 0.9500\n",
      "Epoch 5/30\n",
      "3000/3000 [==============================] - 13s - loss: 2.7307 - acc: 0.8293 - val_loss: 0.7991 - val_acc: 0.9500\n",
      "Epoch 6/30\n",
      "1920/3000 [==================>...........] - ETA: 4s - loss: 3.0026 - acc: 0.8125"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fcdb0b020685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLossHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m model.fit(train_data, train_label, batch_size=batch_size, nb_epoch=nb_epoch,\n\u001b[0;32m---> 46\u001b[0;31m           validation_split=0.25, verbose=1, shuffle=True, callbacks=[history])\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chen/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = np.array([i[0] for i in train])\n",
    "train_label = np.array([i[1] for i in train]) \n",
    "del train\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "sgd= SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "objective = 'binary_crossentropy'\n",
    "def top():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:],name='flatten'))\n",
    "    model.add(Dense(512, activation='relu', name='fc1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu', name='fc2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', name='predictions'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = top()\n",
    "\n",
    "batch_size=64\n",
    "nb_epoch=30\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')        \n",
    "\n",
    "\n",
    "history = LossHistory()\n",
    "model.fit(train_data, train_label, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          validation_split=0.25, verbose=1, shuffle=True, callbacks=[history])\n",
    "model.save('model.h5')\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the test data\n",
    "This part is to build and generate the test data and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:02:04<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "3000/3000 [==============================] - 12s - loss: 3.0892 - acc: 0.8063 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 2/30\n",
      "3000/3000 [==============================] - 12s - loss: 3.3971 - acc: 0.7880 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 3/30\n",
      "3000/3000 [==============================] - 12s - loss: 3.0489 - acc: 0.8097 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 4/30\n",
      "3000/3000 [==============================] - 12s - loss: 3.2263 - acc: 0.7987 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 5/30\n",
      "3000/3000 [==============================] - 12s - loss: 3.2365 - acc: 0.7980 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 6/30\n",
      "3000/3000 [==============================] - 12s - loss: 3.1573 - acc: 0.8030 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 7/30\n",
      "3000/3000 [==============================] - 12s - loss: 3.0880 - acc: 0.8073 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 8/30\n",
      "3000/3000 [==============================] - 12s - loss: 3.0123 - acc: 0.8120 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 9/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1142 - acc: 0.8057 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 10/30\n",
      "3000/3000 [==============================] - 13s - loss: 2.9270 - acc: 0.8173 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 11/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.2267 - acc: 0.7987 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 12/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.2695 - acc: 0.7960 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 13/30\n",
      "3000/3000 [==============================] - 13s - loss: 2.9799 - acc: 0.8140 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 14/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.2688 - acc: 0.7960 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 15/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1249 - acc: 0.8050 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 16/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.0505 - acc: 0.8097 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 17/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.2295 - acc: 0.7983 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 18/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1193 - acc: 0.8053 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 19/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1792 - acc: 0.8017 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 20/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.0557 - acc: 0.8093 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 21/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.0775 - acc: 0.8080 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 22/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.0168 - acc: 0.8117 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 23/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1449 - acc: 0.8037 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 24/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.0753 - acc: 0.8080 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 25/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1992 - acc: 0.8003 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 26/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1724 - acc: 0.8020 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 27/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1036 - acc: 0.8063 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 28/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.1775 - acc: 0.8017 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 29/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.2371 - acc: 0.7980 - val_loss: 1.2178 - val_acc: 0.9240\n",
      "Epoch 30/30\n",
      "3000/3000 [==============================] - 13s - loss: 3.0436 - acc: 0.8100 - val_loss: 1.2178 - val_acc: 0.9240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [30:35<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "test=[]\n",
    "number=range(1,12501)\n",
    "testmodel = VGG16(weights='imagenet', include_top=False)\n",
    "for i in tqdm(number):\n",
    "    img_path=test_dir+''+str(i)+'.jpg'\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    data=testmodel.predict(x)\n",
    "    test.append([np.array(data[0]),np.array(i)])\n",
    "np.save('test.npy',test)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test data\n",
    "This part use the trained model to predict data and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12480/12500 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "\n",
    "test_label=np.array([i[1] for i in test])\n",
    "test_data = np.array([i[0] for i in test])\n",
    "\n",
    "prediction=model.predict(test_data,verbose=1)\n",
    "prediction=prediction.clip(min=0.005, max=0.995)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "for i in range(0,12500):\n",
    "\n",
    "\n",
    "    index = int(test_label[i])\n",
    "    df.set_value(index-1, 'label', prediction[i])\n",
    "\n",
    "df.to_csv('pred.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the image\n",
    "This part draw the image of loss's change when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEZCAYAAACervI0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYjfqPnIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba513b7e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.losses\n",
    "val_loss = history.val_losses\n",
    "fig=plt.figure();\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,nb_epoch)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
